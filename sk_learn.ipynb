{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a SKLearn Model using Script Mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(f\"sagemaker-sample-files\", \"datasets/tabular/iris/iris.data\", \"iris.data\")\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"iris.data\", header=None, names=[\"sepal_len\", \"sepal_wid\", \"petal_len\", \"petal_wid\", \"class\"]\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the three classes from strings to integers in {0,1,2}\n",
    "df[\"class_cat\"] = df[\"class\"].astype(\"category\").cat.codes\n",
    "categories_map = dict(enumerate(df[\"class\"].astype(\"category\").cat.categories))\n",
    "print(categories_map)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80-20 train-test split\n",
    "num_samples = df.shape[0]\n",
    "split = round(num_samples * 0.8)\n",
    "train = df.iloc[:split, :]\n",
    "test = df.iloc[split:, :]\n",
    "print(\"{} train, {} test\".format(split, num_samples - split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write train and test CSV files\n",
    "train.to_csv(\"train.csv\", index=False)\n",
    "test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sagemaker session to upload data to S3\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "# Upload data to default S3 bucket\n",
    "prefix = \"DEMO-sklearn-iris\"\n",
    "training_input_path = sagemaker_session.upload_data(\"train.csv\", key_prefix=prefix + \"/training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the current execution role for training. It needs access to S3\n",
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Docs: https://sagemaker.readthedocs.io/en/stable/frameworks/sklearn/sagemaker.sklearn.html\n",
    "\n",
    "from sagemaker.sklearn import SKLearn\n",
    "\n",
    "sk_estimator = SKLearn(\n",
    "    entry_point=\"train.py\",\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    py_version=\"py3\",\n",
    "    framework_version=\"1.2-1\",\n",
    "    script_mode=True,\n",
    "    hyperparameters={\"estimators\": 20},\n",
    ")\n",
    "\n",
    "# Train the estimator\n",
    "sk_estimator.fit({\"train\": training_input_path})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy and test endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "sk_endpoint_name = \"sklearn-rf-model\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "sk_predictor = sk_estimator.deploy(\n",
    "    initial_instance_count=1, instance_type=\"ml.m5.large\", endpoint_name=sk_endpoint_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "client = sagemaker_session.sagemaker_runtime_client\n",
    "\n",
    "request_body = {\"Input\": [[9.0, 3571, 1976, 0.525]]}\n",
    "data = json.loads(json.dumps(request_body))\n",
    "payload = json.dumps(data)\n",
    "\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=sk_endpoint_name, ContentType=\"application/json\", Body=payload\n",
    ")\n",
    "\n",
    "result = json.loads(response[\"Body\"].read().decode())[\"Output\"]\n",
    "print(\"Predicted class category {} ({})\".format(result, categories_map[result]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_predictor.delete_model()\n",
    "sk_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMaker",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
